{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import gc\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import nnutils_by\n",
    "import importlib\n",
    "importlib.reload(nnutils_by)\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import torch.nn as nn\n",
    "import torchaudio.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for each audio file, store the mel spectrogram and the species that are in it. \n",
    "\n",
    "loop through each audio file and get the mel specs. add it to the list\n",
    "then for each species entry for the given audio file, set the vector of length 24 to have the correct species\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_RATE= 48000\n",
    "BATCH_SIZE = 16\n",
    "VALIDATION_SPLIT = .2\n",
    "SHUFFLE = True\n",
    "RANDOM_SEED = 42\n",
    "LR = 0.001\n",
    "mel_params = {\n",
    "    \"sample_rate\": SAMPLE_RATE,\n",
    "    \"n_fft\": 4096,\n",
    "    \"hop_length\": 2048,\n",
    "    \"n_mels\": 64,\n",
    "    \"f_min\": 0,\n",
    "    \"f_max\": SAMPLE_RATE / 2,\n",
    "    \"power\": 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:  True\n"
     ]
    }
   ],
   "source": [
    "# CUDA\n",
    "is_cuda = True and torch.cuda.is_available()\n",
    "cpu = torch.device('cpu')\n",
    "gpu = torch.device('cuda')\n",
    "device = gpu if is_cuda else cpu\n",
    "\n",
    "print ('cuda: ', is_cuda)\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b6edf55452e42e3abe0e580f288ceda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=4727.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = nnutils_by.MelDataset(mel_params)\n",
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(VALIDATION_SPLIT * dataset_size))\n",
    "if SHUFFLE:\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, \n",
    "                                           sampler=train_sampler)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE,\n",
    "                                                sampler=valid_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(237, 60)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader), len(validation_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (rnn1): LSTM(1407, 64, num_layers=2, batch_first=True)\n",
      "  (l1): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (d1): Dropout(p=0.2, inplace=False)\n",
      "  (out): Linear(in_features=64, out_features=24, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "rnn = nnutils_by.RNN(1407).to(device)\n",
    "rnn.train()\n",
    "print(rnn)\n",
    "\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=LR)   # optimize all cnn parameters\n",
    "loss_func = nn.BCELoss()                     # CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "start_time = time.time()\n",
    "losses = []\n",
    "losses_detail = []\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    # Train:   \n",
    "    running_loss = 0.0\n",
    "#     t = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}, running loss: {running_loss}\")\n",
    "\n",
    "    for batch_index, (inputs, labels, _) in enumerate(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "#         print(inputs.shape)\n",
    "        inputs = inputs.reshape(-1, 64, 1407)\n",
    "#         print(inputs.shape)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = rnn(inputs)\n",
    "        loss = loss_func(output, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        del inputs\n",
    "        del labels\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        losses_detail.append(loss.item())\n",
    "        loss_interval = 50\n",
    "        if batch_index % loss_interval == 0:    # print every 50 mini-batches\n",
    "            #print('[%d %5d] loss: %.3f' % (epoch+1, i+1, running_loss / 50))\n",
    "            interval_loss = running_loss/loss_interval\n",
    "            losses.append(interval_loss)\n",
    "#             t.set_description(f\"\")\n",
    "#             print(f\"Epoch {batch_index}/{num_epochs}, running_loss: {interval_loss:{2}.{5}}\")\n",
    "#             t.refresh()\n",
    "            running_loss = 0.0\n",
    "    print(f\"Epoch {epoch}/{num_epochs}, running_loss: {running_loss:{2}.{5}}\")\n",
    "        \n",
    "end_time = time.time()\n",
    "print ('\\n-------- DONE --------')\n",
    "print ('start time: {}'.format(start_time))\n",
    "print ('end time: {}\\n'.format(end_time))\n",
    "\n",
    "duration = end_time-start_time\n",
    "print ('training duration: {}'.format(str(timedelta(seconds=duration))))\n",
    "\n",
    "model_path = 'models/rainforest{}.pt'.format(end_time)\n",
    "torch.save(rnn.state_dict(), model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(nnutils_by)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51f38f9667d24ed88bb8ca78e2724062",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=60.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28db1156736b4037970bd0c1b1fd7c38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=945.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_path = \"models/rainforest1609024664.0753264.pt\"\n",
    "\n",
    "valid_model = nnutils_by.RNN(1407)\n",
    "valid_model.load_state_dict(torch.load(model_path))\n",
    "valid_model.eval()\n",
    "valid_model = valid_model.to(device)\n",
    "\n",
    "valid_results = pd.DataFrame()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(tqdm(validation_loader)):\n",
    "        inputs, labels, audio_ids = data\n",
    "        inputs, labels, audio_ids = inputs.to(device), labels.to(device), audio_ids\n",
    "        for ind in range(inputs.shape[0]):\n",
    "            outputs = valid_model(inputs[ind])\n",
    "            res = outputs[0].to(cpu).numpy()\n",
    "\n",
    "            valid_results = valid_results.append({ 'result': res , 'recording_id' : audio_ids[ind]}, ignore_index=True)\n",
    "        \n",
    "    submission = pd.DataFrame()\n",
    "    \n",
    "\n",
    "    for idx in tqdm(range(len(valid_results))):\n",
    "        \n",
    "        ex = valid_results.iloc[idx]\n",
    "        recording_id = ex.recording_id\n",
    "        result = ex.result\n",
    "\n",
    "        species = 0\n",
    "        o = {}\n",
    "        for r in result:\n",
    "            s = 's{}'.format(species)\n",
    "            o[s] = r\n",
    "            species += 1 \n",
    "        o[\"recording_id\"] = recording_id\n",
    "        submission = submission.append(o, ignore_index=True)\n",
    "    \n",
    "    del valid_results\n",
    "    cols = ['recording_id', 's0', 's1', 's2', 's3', 's4', 's5', 's6', 's7', 's8', 's9', 's10', 's11', 's12', 's13', 's14', 's15', 's16', 's17', 's18', 's19', 's20', 's21', 's22', 's23']\n",
    "    submission = submission[cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(945, 25)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(nan, 0.23523449160696627)\n"
     ]
    }
   ],
   "source": [
    "from utils import score\n",
    "s = score(submission)\n",
    "print(s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
