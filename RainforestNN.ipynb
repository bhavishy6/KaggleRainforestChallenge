{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchaudio\n",
    "import torchaudio.models as models\n",
    "import torchvision.models as vmodels\n",
    "import torchaudio.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import glob\n",
    "import librosa\n",
    "import librosa.display\n",
    "import soundfile as sf\n",
    "from scipy.interpolate import interp1d\n",
    "import IPython.display as ipd\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "EPOCHS = 1\n",
    "TRAIN_BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## need to work on padding tensors to have consistent shape\n",
    "\n",
    "class MelSpecDataset(Dataset):\n",
    "    def __init__(self, source_file):\n",
    "        self.source = pd.read_csv(source_file)\n",
    "        \n",
    "        mel_specs = []\n",
    "        wvs = []\n",
    "        for idx in range(len(self.source)):\n",
    "            ex = self.source.iloc[idx]\n",
    "            waveform = ex.waveform\n",
    "\n",
    "            if isinstance(waveform, str): \n",
    "                wv = ','.join(ex.waveform.replace('[ ', '[').split())\n",
    "                wv = np.array(ast.literal_eval(wv))\n",
    "                waveform = torch.from_numpy(wv).view(1, -1).to(dtype=torch.float32)\n",
    "\n",
    "                wvs.append(waveform)\n",
    "\n",
    "            sample_rate = int(ex.sample_rate)\n",
    "            \n",
    "            waveform = waveform.view(1, 1, -1)\n",
    "            mel_spec = transforms.MelSpectrogram(sample_rate=sample_rate)(waveform).repeat(1, 3, 1, 1)\n",
    "            #mfcc = librosa.feature.mfcc(y=wv, sr=ex.sample_rate)\n",
    "\n",
    "            mel_specs.append(mel_spec)\n",
    "\n",
    "        if 'mel_spec' in self.source:\n",
    "            self.source = self.source.assign(mel_spec=mel_specs)\n",
    "        else:\n",
    "            self.source.insert(4, \"mel_spec\", mel_specs, True)\n",
    "        if len(wvs) > 0:\n",
    "            self.source = self.source.assign(waveform=wvs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        ex = self.source.iloc[idx]\n",
    "        return (ex.mel_spec, ex.species_id)\n",
    "    def __len__(self):\n",
    "        return len(self.source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda?:  True\n"
     ]
    }
   ],
   "source": [
    "# CUDA\n",
    "is_cuda = True and torch.cuda.is_available()\n",
    "device = torch.device('cuda') if is_cuda else torch.device('cpu')\n",
    "\n",
    "print ('cuda?: ', is_cuda)\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = MelSpecDataset('train_classified-10.csv')\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=TRAIN_BATCH_SIZE,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = vmodels.resnet50(pretrained=True).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(resnet.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.9114532470703125\n",
      "7.147956371307373\n",
      "7.438002586364746\n",
      "7.384486198425293\n",
      "7.979250907897949\n",
      "7.059122085571289\n",
      "8.262460708618164\n",
      "7.255756378173828\n",
      "7.6105055809021\n",
      "7.416545867919922\n",
      "8.055137634277344\n"
     ]
    }
   ],
   "source": [
    "# when tensors are of the same shape from the dataset, will use trainloader instead of trainset directly\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for i, data in enumerate(trainset):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), torch.tensor([int(labels)]).to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "                \n",
    "        output = resnet(inputs)\n",
    "        \n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        print (loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_classified = pd.read_csv('train_classified-10.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate mfccs and parse waveform\n",
    "# build relevant dataset for pytorch\n",
    "\n",
    "# mel_specs = []\n",
    "# wvs = []\n",
    "# for idx in range(len(train_classified)):\n",
    "#     ex = train_classified.iloc[idx]\n",
    "#     waveform = ex.waveform\n",
    "    \n",
    "#     if isinstance(waveform, str): \n",
    "#         wv = ','.join(ex.waveform.replace('[ ', '[').split())\n",
    "#         wv = np.array(ast.literal_eval(wv))\n",
    "#         waveform = torch.from_numpy(wv).view(1, -1).to(dtype=torch.float32)\n",
    "\n",
    "#         wvs.append(waveform)\n",
    "    \n",
    "#     sample_rate = int(ex.sample_rate)\n",
    "    \n",
    "#     mel_spec = transforms.MelSpectrogram(sample_rate=sample_rate)(waveform)\n",
    "#     #mfcc = librosa.feature.mfcc(y=wv, sr=ex.sample_rate)\n",
    "    \n",
    "#     mel_specs.append(mel_spec)\n",
    "    \n",
    "# if 'mel_spec' in train_classified:\n",
    "#     train_classified = train_classified.assign(mel_spec=mel_specs)\n",
    "# else:\n",
    "#     train_classified.insert(4, \"mel_spec\", mel_specs, True)\n",
    "# if len(wvs) > 0:\n",
    "#     train_classified = train_classified.assign(waveform=wvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_classified.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet = vmodels.resnet50(pretrained=True).to(device)\n",
    "# for idx in range(len(train_classified)):\n",
    "#     ex = train_classified.iloc[idx]\n",
    "    \n",
    "#     mel_spec = ex.mel_spec.repeat(1, 3, 1, 1).to(device)\n",
    "#     print (mel_spec.shape)\n",
    "    \n",
    "#     output = resnet(mel_spec)\n",
    "    \n",
    "#     print (output.shape)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA\n",
    "# is_cuda = True and torch.cuda.is_available()\n",
    "# device = torch.device('cuda') if is_cuda else torch.device('cpu')\n",
    "\n",
    "# print ('cuda?: ', is_cuda)\n",
    "\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "# res = vmodels.resnet50(pretrained=True).to(device)\n",
    "\n",
    "# waveform, sample_rate = torchaudio.load('data/train\\\\00204008d.flac')\n",
    "# waveform = waveform.view(1, 1, -1)\n",
    "# #print (waveform)\n",
    "# mel = transforms.MelSpectrogram(sample_rate=sample_rate)(waveform).repeat(1, 3, 1, 1)\n",
    "\n",
    "# mel = mel.to(device)\n",
    "\n",
    "# print (waveform.shape)\n",
    "# print (mel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     output = res(mel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize\n",
    "\n",
    "# for idx in range(len(train_classified)):\n",
    "#     ex = train_classified.iloc[idx]\n",
    "#     mfcc = ex.mfcc\n",
    "#     fig, ax = plt.subplots()\n",
    "#     img = librosa.display.specshow(mfcc, x_axis='time', ax=ax)\n",
    "#     fig.colorbar(img, ax=ax)\n",
    "#     ax.set(title='MFCC')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rainforest_proj",
   "language": "python",
   "name": "rainforest_proj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
